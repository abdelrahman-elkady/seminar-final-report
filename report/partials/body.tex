\section{Introduction}
\label{sec:intro}

Topic understanding is processed and evaluated using many methods and techniques. One study to understand topic models is by evaluating and
generating labels for different topic models classified manually or programmatically. In this study, an evaluation of different visual evaluation techniques
for labeling and assessing the correctness of generated labels is conducted. Running over four different visualization techniques, and evaluating them
over two phases, the labeling phase, where users are labeling the topics using the visualization technique. And the validation phase, where users are
measuring and selecting best matching labels from the ones generated in the first phase.

\section{Background}
\label{sec:bg}

Research in labeling different topic models is being conducted in order to produce high quality labels automatically. Algorithms are implemented
to generate labels for topic models based on probabilistic approaches. Generating labels
is done using wikipedia for example to get the corpus and apply probabilistic measurements and match it with the similar wikipedia page
However, validating the quality of generated labels is still a challenge, compared to the manually generated labels.

\newParagraph
In this study, the four visualization techniques mentioned below are used for manual labeling, clustering and modeling the corpus is executed using the
Latent Dirichlet Allocation (LDA) algorithm. LDA works by analyzing the whole document and then apply probabilistic measurement to cluster different documents
in the corpora into different clusters.

\includefig{0.85}{all-vis.png}{Visual labeling methods}{fig:viss}
\newParagraph
The visual techniques evaluated in this study are represented in Figure.\ref{fig:viss}, they are described as follows:
\begin{itemize}
  \item Word list
  \item Word list with bars
  \item Word cloud
  \item Network Graph
\end{itemize}

\newParagraph
Each method is tested against three classes of cardinality, with 5, 10 and 20 words. Results are calculated and measured for next phase along with the automatically
generated labels for the same cardinalities.

\section{Method and execution}
\label{sec:method}

The study is conducted online, comparing different visualization techniques on different cardinalities. The data input for this study is collected from New
 York Times articles, gathering 7,156 article from January 2007. The clustering of topics is executed using the LDA algorithm, while the automatic labeling
 is done using the wikipedia article technique discussed previously. The manual labeling is done using Amazon Mechanical Turk as  Human Intelligence Tasks (HIT)
 .

\newParagraph
The different visualization techniques discussed above are used to label different topics in phase 1. All the visual methods are kept in 400 x 250 pixel space
to have a consistent comparison. Different methods are discussed below

\subsection{Word List}
Is the simplest technique of the four. It is a simple word enumeration with each word on a separate line, all equally sized, ordered by probability of occurrence
in the topic. Words are organized in two columns to fit in the space provided efficiently. Numbers are added beside each word to enforce the order and to avoid
ambiguity that could occur due to the two column layout.

\subsection{Word List with bars}
This technique is the same as the word list, while maintaining bars beside each word to indicate its order by probability in the topic.

\subsection{Word Cloud}
The word cloud represents each word with its probability in the topic affecting its size, words with higher probability in the topic are assigned larger font
size, while words with less probability are assigned smaller font sizes. When the word is too large to fit in the space, words are scaled accordingly to maintain
the ratio of word size based on the probability of occurrence in the topic. All words are displayed horizontally with some gray scale to increase readability of
word tags.

\subsection{Network Graph}
This technique is the most sophisticated and complex representation, it represents each word in the topic as a node in the graph, while each topic is an
edge between different nodes. The radius of the nodes is scaled by a ratio calculated according to the probability of word occurrence in the topic. Width and
color of edges is kept constant to reduce the complexity of the representation.


\newParagraph
The first phase of the study is the labeling phase, where manual labeling of different topics is applied using different visualization techniques. Part of the
dataset have labels assigned automatically too using the Wikipedia algorithm. Users are asked to give a short label describing the topic, and then have a longer
sentence as a further description for the topic. Also, users are asked to represent their confidence of their labeling by choosing a value from a scale from 1 to 5
representing their confidence in their provided label and description of the topic. Each task for a user have 5 labeling tasks from the same visualization technique.

\newParagraph
The second task is the validation phase. where a new set of users are asked to measure the quality and accuracy of labels generated in phase 1, including the
automatically generated ones. The study in phase one had three cardinality levels, for the four techniques, generating twelve combination of tasks. Five users
are doing the labeling task for each topic from the fifty topic in the study, resulting in a minimum of 3,000 user labeling tasks. With each task having five
tasks from the same visualization technique. In the second phase, 3,212 label is collected from phase one. They are evaluated into 1,500 validation task, without
allowing duplication of topic/label comparisons. 
